# Q-Sentinel: Robust Quantumâ€“Classical Defenses for O-RAN

This repository contains the research code, experiments, and visual assets for **Q-Sentinel**, a layered defense stack that hardens hybrid quantumâ€“classical (QC) xApps against RF interference attacks in Open RAN (O-RAN) deployments. The project benchmarks clean training, adversarial training (QAT), and the proposed Q-Sentinel approach across gradient-based (QC-FGSM/PGD) and circuit-poisoning threats, demonstrating superior robustness with minimal loss in clean accuracy.

> ğŸ”¬ **Core idea:** Combine quantum state tomography (QST), fidelity-aware drift-balancing regularization (Q-DBR), and sentinel snapshots with cosine-drift auto-repair to maintain a wide quantum decision margin under adaptive adversaries.

---

## Highlights
- **Hybrid QC xApp** built with PyTorch, fusing classical ResNet feature extractors and 6-qubit variational circuits (`quantum_classical_hybrid.py`).
- **Defense suite** including baseline, QAT, and Q-Sentinel trainers with configurable adversaries (see `qs_sentinel.py`, `defense_utils.py`).
- **Reproducible pipeline** (`qsentinel_train_eval.py`) that trains each scenario, evaluates robustness across an epsilon grid, and generates publication-ready plots/tables.
- **Comprehensive visualization assets** in `figures/`, `spectrogram-dataset/soi/`, and `reports_qs/` for inclusion in papers, slides, and posters.
- **Meeting-ready slides** (`qsentinel_results_slides.tex`) capturing evaluation results, expert discussion, and next steps.

---

## Repository Layout

```
.
â”œâ”€â”€ data/                         # Clean SOI/CWI spectrogram data (placeholder paths)
â”œâ”€â”€ quantum_classical_hybrid.py   # Hybrid model definition + configuration dataclass
â”œâ”€â”€ data_handler.py               # Data loader utilities and augmentations
â”œâ”€â”€ defense_utils.py              # Adversarial example generation + Q-DBR objective
â”œâ”€â”€ qs_sentinel.py                # Trainers, configs, evaluation helpers
â”œâ”€â”€ qsentinel_train_eval.py       # End-to-end experiment runner + reporting
â”œâ”€â”€ figures/                      # Baseline learning curve and other figures
â”œâ”€â”€ spectrogram-dataset/soi/      # Robustness plots (accuracy vs Îµ, ASR, etc.)
â”œâ”€â”€ reports_qs/                   # Generated CSV/plot outputs (after running pipeline)
â”œâ”€â”€ qsentinel_results_slides.tex  # Beamer slides for evaluation discussion
â”œâ”€â”€ env.yml / requirements.txt    # Conda + pip dependency specifications
â””â”€â”€ README.md                     # This overview
```

---

## Environment Setup

```bash
# 1) Clone your fork
git clone https://github.com/<user>/q-sentinel.git
cd q-sentinel

# 2) Create the environment (preferred: Conda)
conda env create -f env.yml
conda activate qsentinel

# 3) Alternatively (pip)
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

The experiments expect access to spectrogram datasets for signal-of-interest (SOI) and co-channel interference (CWI). Update the default paths in `qsentinel_train_eval.py` or provide `--soi-dir` and `--cwi-dir` on the CLI.

---

## Quickstart: Reproduce the Benchmark

```bash
python qsentinel_train_eval.py \
    --epochs 25 \
    --batch-size 16 \
    --image-size 224 \
    --soi-dir data/soi \
    --cwi-dir data/cwi \
    --output-dir reports_qs
```

This command:
- Trains the **baseline**, **QAT**, and **Q-Sentinel** models on the provided spectrogram data.
- Evaluates clean accuracy plus QC-FGSM, QC-PGD, and QC-Poison worst-case accuracy/ASR across Îµ âˆˆ {0.01,â€¦,0.10}.
- Exports JSON histories, `robustness_metrics.csv`, and plots (`training_dynamics.*`, `accuracy_vs_epsilon.*`, `qc_poison_scatter.*`) into `reports_qs/`.

Use the saved `robustness_metrics.csv` for tables or load it into notebooks (`QuantumHybrid_Train.ipynb`, `quantum_classical_hybrid.ipynb`) for deeper analysis.

## Key Results

| Scenario | Clean Acc. | FGSM Acc<sub>min</sub> | FGSM ASR | PGD Acc<sub>min</sub> | PGD ASR | QC-Poison Acc<sub>min</sub> / â€–Î”Î¸â€–<sub>âˆ</sub> |
|----------|------------|------------------------|----------|------------------------|---------|-----------------------------------------------|
| Baseline | 0.982 | 0.558 | 0.442 | **0.160** | 0.639 | **0.708** / 3.1Ã—10â»Â² |
| QAT (PGD)| 0.948 | 0.804 | 0.196 | 0.692 | 0.308 | 0.611 / 2.6Ã—10â»Â² |
| **Q-Sentinel** | **0.974** | **0.847** | **0.153** | **0.736** | **0.264** | **0.708 / 1.8Ã—10â»Â²** |

- Q-Sentinel narrows the worst-case gap by â‰ˆ4â€“5 percentage points beyond QAT while halving Hilbert-space drift under QC-Poison.
- Clean accuracy remains near 98%, demonstrating that robustness does not compromise nominal performance.
- Figures `spectrogram-dataset/soi/naccuracy_vs_epsilon_ieee.pdf` and `spectrogram-dataset/soi/asr_qcpoison_comparison.pdf` visualize the collapse of undefended models versus the flat response of Q-Sentinel.

---

## Citing This Work

# Q-Sentinel + Quantum State Poisoning-Adversarial Attacks 


## Overview
This project implements a quantum state poisoning algorithm designed to explore adversarial attacks in quantum machine learning using the **PennyLane** framework. The algorithm modifies quantum states through angle phase-shifting, demonstrating how small perturbations can impact the performance of quantum models.
## AE Structure and VQC Layer
![QI-attacks1-qtn_Poisoning 1-1](https://github.com/user-attachments/assets/d9249b24-77d0-4c7c-8f2e-798c220fc8b7)

## Features
- **Quantum Circuit Implementation**: Utilizes PennyLane for customizable quantum circuit design.
- **Angle Phase-Shifting**: Applies perturbations to rotation angles to create adversarial states.
- **Fidelity Evaluation**: Computes fidelity between original and adversarial states to assess attack effectiveness.
- **Dynamic Perturbation Adjustment**: Updates perturbations based on fidelity thresholds to refine attacks.
- The core perturbation is modeled as a quantum phase transition.
  ![VQc-1](https://github.com/user-attachments/assets/41f55af2-0274-4da5-bf6e-9a2a2869431a)
## Algorithm
The core algorithm is structured as follows:
1. **Initialization**: Prepares the initial quantum state.
2. **Layer and Qubit Iteration**: Iterates through each layer and qubit to apply perturbations.
3. **Adversarial Angle Calculation**: Modifies angles to create adversarial perturbations.
4. **State Update and Fidelity Calculation**: Updates the quantum state and computes fidelity.
5. **Perturbation Adjustment**: Dynamically adjusts perturbations based on fidelity results.

Refer to the algorithm section in the code for detailed implementation.

The dataset can be found here: https://www.nextgwirelesslab.org/datasets
## Requirements
- Python 3.8.20
- PennyLane
- Tensorflow

## Installation
Clone the repository and install the required packages:
```bash
git clone https://github.com/Jaredabera/quantum-state-poisoning.git
```
There are 2 conda environment discription files for easily reconstructing the dependencies.
```bash
conda env create -f <env-file>
```
This technique opens new avenues for:

- Studying adversarial robustness in quantum-classical hybrid systems
- Understanding the relationship between quantum phenomena and adversarial examples
- Developing quantum-hybrid defenses against classical attacks
