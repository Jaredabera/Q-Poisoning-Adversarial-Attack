{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# Configuration & Setup\n",
    "# ----------------------\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Dataset Class\n",
    "# --------------------\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, soi_dir, cwi_dir, transform=None):\n",
    "        self.filepaths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Load SOI images (label 0)\n",
    "        for fname in os.listdir(soi_dir):\n",
    "            self.filepaths.append(os.path.join(soi_dir, fname))\n",
    "            self.labels.append(0)\n",
    "            \n",
    "        # Load CWI images (label 1)\n",
    "        for fname in os.listdir(cwi_dir):\n",
    "            self.filepaths.append(os.path.join(cwi_dir, fname))\n",
    "            self.labels.append(1)\n",
    "            \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.filepaths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Data Preparation\n",
    "# ----------------------\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Initialize dataset\n",
    "soi_dir = '/home/HardDisk/yared/spectrogram-dataset/soi'\n",
    "cwi_dir = '/home/HardDisk/yared/spectrogram-dataset/cwi'\n",
    "full_dataset = SpectrogramDataset(soi_dir, cwi_dir, data_transforms)\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Quantum Components\n",
    "# --------------------\n",
    "n_qubits = 6\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_circuit(inputs, weights):\n",
    "    # Input encoding\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(inputs[i], wires=i)\n",
    "    \n",
    "    # Variational layers\n",
    "    qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "    \n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/Pennylane/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ea301b/anaconda3/envs/Pennylane/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# Hybrid Model\n",
    "# ----------------------\n",
    "class HybridQNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Classical components with frozen ResNet\n",
    "        self.resnet = torchvision.models.resnet18(pretrained=True)\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        \n",
    "        # Trainable post-processing\n",
    "        self.post_resnet = nn.Sequential(\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, n_qubits)\n",
    "        )\n",
    "        \n",
    "        # Quantum components\n",
    "        weight_shape = {\"weights\": (3, n_qubits, 3)}\n",
    "        self.qlayer = qml.qnn.TorchLayer(quantum_circuit, weight_shapes=weight_shape)\n",
    "        \n",
    "        # Final classifier\n",
    "        self.classifier = nn.Linear(n_qubits, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Allow gradient flow through feature extractor\n",
    "        with torch.set_grad_enabled(True):  # Critical for attack gradients\n",
    "            x = self.resnet(x).flatten(1)\n",
    "        x = self.post_resnet(x)\n",
    "        x = self.qlayer(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Initialize model\n",
    "model = HybridQNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 | Train Loss: 0.4528 | Val Loss: 0.3358 | Accuracy: 93.51%\n",
      "Epoch 2/25 | Train Loss: 0.2801 | Val Loss: 0.2125 | Accuracy: 94.31%\n",
      "Epoch 3/25 | Train Loss: 0.2121 | Val Loss: 0.2021 | Accuracy: 94.19%\n",
      "Epoch 4/25 | Train Loss: 0.1888 | Val Loss: 0.2068 | Accuracy: 92.78%\n",
      "Epoch 5/25 | Train Loss: 0.1871 | Val Loss: 0.1573 | Accuracy: 95.17%\n",
      "Epoch 6/25 | Train Loss: 0.1690 | Val Loss: 0.1532 | Accuracy: 95.29%\n",
      "Epoch 7/25 | Train Loss: 0.1504 | Val Loss: 0.1555 | Accuracy: 95.47%\n",
      "Epoch 8/25 | Train Loss: 0.1509 | Val Loss: 0.1409 | Accuracy: 95.10%\n",
      "Epoch 9/25 | Train Loss: 0.1524 | Val Loss: 0.1427 | Accuracy: 95.10%\n",
      "Epoch 10/25 | Train Loss: 0.1438 | Val Loss: 0.1452 | Accuracy: 94.74%\n",
      "Epoch 11/25 | Train Loss: 0.1398 | Val Loss: 0.1387 | Accuracy: 95.10%\n",
      "Epoch 12/25 | Train Loss: 0.1197 | Val Loss: 0.1425 | Accuracy: 95.29%\n",
      "Epoch 13/25 | Train Loss: 0.1308 | Val Loss: 0.1702 | Accuracy: 94.06%\n",
      "Epoch 14/25 | Train Loss: 0.1218 | Val Loss: 0.1567 | Accuracy: 94.98%\n",
      "Epoch 15/25 | Train Loss: 0.1125 | Val Loss: 0.1452 | Accuracy: 95.29%\n",
      "Epoch 16/25 | Train Loss: 0.1115 | Val Loss: 0.1650 | Accuracy: 94.19%\n",
      "Epoch 17/25 | Train Loss: 0.1149 | Val Loss: 0.1529 | Accuracy: 94.80%\n",
      "Epoch 18/25 | Train Loss: 0.1070 | Val Loss: 0.1305 | Accuracy: 95.47%\n",
      "Epoch 19/25 | Train Loss: 0.1111 | Val Loss: 0.1375 | Accuracy: 95.04%\n",
      "Epoch 20/25 | Train Loss: 0.1112 | Val Loss: 0.1451 | Accuracy: 95.29%\n",
      "Epoch 21/25 | Train Loss: 0.1047 | Val Loss: 0.1505 | Accuracy: 94.86%\n",
      "Epoch 22/25 | Train Loss: 0.1005 | Val Loss: 0.1496 | Accuracy: 95.04%\n",
      "Epoch 23/25 | Train Loss: 0.1008 | Val Loss: 0.1462 | Accuracy: 95.65%\n",
      "Epoch 24/25 | Train Loss: 0.0919 | Val Loss: 0.1470 | Accuracy: 95.41%\n",
      "Epoch 25/25 | Train Loss: 0.0920 | Val Loss: 0.1383 | Accuracy: 95.53%\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# Training Loop\n",
    "# ----------------------\n",
    "def train_model(model, epochs=25):\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        val_loss = val_loss / len(test_loader.dataset)\n",
    "        val_acc = correct / total\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "              f\"Accuracy: {val_acc:.2%}\")\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "# Start training\n",
    "train_losses, val_losses = train_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Quantum-State Poisoning attack with adaptive perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def quantum_aware_attack(model, x, y_true, target_class=1, epsilon=0.3, n_iter=10, temp=0.2):\n",
    "    \"\"\"quantum-state poisoning attack with adaptive perturbation\"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Store original quantum parameters\n",
    "    quantum_weights = model.qlayer.weights\n",
    "    q_weights_orig = quantum_weights.detach().clone()\n",
    "    \n",
    "    best_conf = 0\n",
    "    best_pred = y_true.item()\n",
    "    adaptive_eps = epsilon\n",
    "    \n",
    "    for _ in range(n_iter):\n",
    "        # Enable gradient computation\n",
    "        with torch.set_grad_enabled(True):\n",
    "            x.requires_grad = True\n",
    "            model.zero_grad()\n",
    "            \n",
    "            # Forward pass with current weights\n",
    "            output = model(x)\n",
    "            loss = nn.CrossEntropyLoss()(output, torch.tensor([target_class]).to(device))\n",
    "            loss.backward()\n",
    "            \n",
    "            # Get quantum gradients\n",
    "            grad_q = quantum_weights.grad\n",
    "            if grad_q is None:\n",
    "                continue\n",
    "                \n",
    "            # Quantum-aware perturbation\n",
    "            q_sensitivity = torch.sigmoid(torch.abs(grad_q) / temp)\n",
    "            \n",
    "            # Entanglement pattern boosting\n",
    "            weight_diff = quantum_weights - torch.mean(quantum_weights, dim=1, keepdim=True)\n",
    "            ent_boost = 1 + torch.norm(weight_diff, p=2, dim=2)\n",
    "            q_sensitivity *= ent_boost[:,:,None]\n",
    "            \n",
    "            # Apply adaptive perturbation\n",
    "            delta = adaptive_eps * grad_q * q_sensitivity\n",
    "            new_weights = q_weights_orig + delta\n",
    "            \n",
    "            # Evaluate perturbed model\n",
    "            with torch.no_grad():\n",
    "                quantum_weights.copy_(new_weights)\n",
    "                conf = torch.softmax(model(x), 1)[0, target_class].item()\n",
    "                current_pred = model(x).argmax().item()\n",
    "                \n",
    "                if conf > best_conf:\n",
    "                    best_conf = conf\n",
    "                    best_pred = current_pred\n",
    "                \n",
    "                # Dynamic epsilon adjustment\n",
    "                adaptive_eps *= 0.8 if current_pred == target_class else 1.2\n",
    "    \n",
    "    # Restore original weights\n",
    "    with torch.no_grad():\n",
    "        quantum_weights.copy_(q_weights_orig)\n",
    "        \n",
    "    return best_pred, best_conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model, test_loader, attack_strength=None, target_class=1):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_confidences = []\n",
    "    \n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        batch_preds = []\n",
    "        for i in range(len(inputs)):\n",
    "            x = inputs[i].unsqueeze(0)\n",
    "            y = labels[i]\n",
    "            \n",
    "            if attack_strength is None or y.item() == target_class:\n",
    "                # Clean evaluation\n",
    "                with torch.no_grad():\n",
    "                    output = model(x)\n",
    "                    pred = output.argmax().item()\n",
    "                    conf = torch.softmax(output, 1)[0, pred].item()\n",
    "            else:\n",
    "                # Attack scenario\n",
    "                pred, conf = quantum_aware_attack(\n",
    "                    model, x, y, \n",
    "                    target_class=target_class,\n",
    "                    epsilon=attack_strength,\n",
    "                    n_iter=10,\n",
    "                    temp=0.2\n",
    "                )\n",
    "            \n",
    "            batch_preds.append(pred)\n",
    "            all_confidences.append(conf)\n",
    "        \n",
    "        all_preds.extend(batch_preds)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'accuracy': np.mean(np.array(all_preds) == np.array(all_labels)),\n",
    "        'precision': precision_score(all_labels, all_preds, zero_division=0),\n",
    "        'recall': recall_score(all_labels, all_preds, zero_division=0),\n",
    "        'f1': f1_score(all_labels, all_preds, zero_division=0),\n",
    "        'roc_auc': roc_auc_score(all_labels, all_preds),\n",
    "        'avg_confidence': np.mean(all_confidences),\n",
    "        'attack_success': np.mean([p == target_class for p, l in zip(all_preds, all_labels) if l != target_class])\n",
    "    }\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_attack_scenarios(model, test_loader):\n",
    "    attack_strengths = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1]\n",
    "    results = {}\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Quantum-Aware Attack Evaluation\".center(60))\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    for eps in attack_strengths:\n",
    "        key = 'Clean' if eps == 0.0 else f'Œµ={eps:.2f}'\n",
    "        print(f\"üîç Processing {key} scenario...\")\n",
    "        \n",
    "        results[key] = compute_metrics(\n",
    "            model, \n",
    "            test_loader, \n",
    "            attack_strength=None if eps == 0.0 else eps,\n",
    "            target_class=1\n",
    "        )\n",
    "        \n",
    "        # Print formatted results\n",
    "        print(f\"\\nüìä {key} Results:\")\n",
    "        print(\"-\"*50)\n",
    "        for metric, value in results[key].items():\n",
    "            if metric == 'attack_success':\n",
    "                print(f\"{'Attack Success Rate':>20}: {value:.2%}\")\n",
    "            else:\n",
    "                print(f\"{metric:>20}: {value:.4f}\")\n",
    "        print()\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "              Quantum-Aware Attack Evaluation               \n",
      "============================================================\n",
      "\n",
      "üîç Processing Clean scenario...\n",
      "\n",
      "üìä Clean Results:\n",
      "--------------------------------------------------\n",
      "            accuracy: 0.9547\n",
      "           precision: 0.9624\n",
      "              recall: 0.8668\n",
      "                  f1: 0.9121\n",
      "             roc_auc: 0.9271\n",
      "      avg_confidence: 0.9645\n",
      " Attack Success Rate: 1.26%\n",
      "\n",
      "üîç Processing Œµ=0.01 scenario...\n",
      "\n",
      "üìä Œµ=0.01 Results:\n",
      "--------------------------------------------------\n",
      "            accuracy: 0.9590\n",
      "           precision: 0.9796\n",
      "              recall: 0.8668\n",
      "                  f1: 0.9198\n",
      "             roc_auc: 0.9301\n",
      "      avg_confidence: 0.2711\n",
      " Attack Success Rate: 0.67%\n",
      "\n",
      "üîç Processing Œµ=0.02 scenario...\n",
      "\n",
      "üìä Œµ=0.02 Results:\n",
      "--------------------------------------------------\n",
      "            accuracy: 0.2760\n",
      "           precision: 0.2546\n",
      "              recall: 0.8668\n",
      "                  f1: 0.3936\n",
      "             roc_auc: 0.4615\n",
      "      avg_confidence: 0.8767\n",
      " Attack Success Rate: 94.37%\n",
      "\n",
      "üîç Processing Œµ=0.03 scenario...\n",
      "\n",
      "üìä Œµ=0.03 Results:\n",
      "--------------------------------------------------\n",
      "            accuracy: 0.2375\n",
      "           precision: 0.2444\n",
      "              recall: 0.8668\n",
      "                  f1: 0.3813\n",
      "             roc_auc: 0.4351\n",
      "      avg_confidence: 0.9100\n",
      " Attack Success Rate: 99.66%\n",
      "\n",
      "üîç Processing Œµ=0.04 scenario...\n",
      "\n",
      "üìä Œµ=0.04 Results:\n",
      "--------------------------------------------------\n",
      "            accuracy: 0.2387\n",
      "           precision: 0.2447\n",
      "              recall: 0.8668\n",
      "                  f1: 0.3817\n",
      "             roc_auc: 0.4359\n",
      "      avg_confidence: 0.9045\n",
      " Attack Success Rate: 99.50%\n",
      "\n",
      "üîç Processing Œµ=0.05 scenario...\n",
      "\n",
      "üìä Œµ=0.05 Results:\n",
      "--------------------------------------------------\n",
      "            accuracy: 0.2405\n",
      "           precision: 0.2452\n",
      "              recall: 0.8668\n",
      "                  f1: 0.3823\n",
      "             roc_auc: 0.4372\n",
      "      avg_confidence: 0.8823\n",
      " Attack Success Rate: 99.24%\n",
      "\n",
      "üîç Processing Œµ=0.10 scenario...\n",
      "\n",
      "üìä Œµ=0.10 Results:\n",
      "--------------------------------------------------\n",
      "            accuracy: 0.2399\n",
      "           precision: 0.2451\n",
      "              recall: 0.8668\n",
      "                  f1: 0.3821\n",
      "             roc_auc: 0.4368\n",
      "      avg_confidence: 0.8422\n",
      " Attack Success Rate: 99.33%\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                     Quantum Attack Performance Comparison                      \n",
      "================================================================================\n",
      "Scenario  Accuracy    F1          ROC AUC     Attack Success Avg Conf    \n",
      "--------------------------------------------------------------------------------\n",
      "Clean     0.9547  0.9121  0.9271  1.26%   0.9645\n",
      "Œµ=0.01    0.9590  0.9198  0.9301  0.67%   0.2711\n",
      "Œµ=0.02    0.2760  0.3936  0.4615  94.37%   0.8767\n",
      "Œµ=0.03    0.2375  0.3813  0.4351  99.66%   0.9100\n",
      "Œµ=0.04    0.2387  0.3817  0.4359  99.50%   0.9045\n",
      "Œµ=0.05    0.2405  0.3823  0.4372  99.24%   0.8823\n",
      "Œµ=0.10    0.2399  0.3821  0.4368  99.33%   0.8422\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "attack_results = evaluate_attack_scenarios(model, test_loader)\n",
    "\n",
    "# Generate comparison table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Quantum Attack Performance Comparison\".center(80))\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Scenario':<10}{'Accuracy':<12}{'F1':<12}{'ROC AUC':<12}{'Attack Success':<15}{'Avg Conf':<12}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for scenario, metrics in attack_results.items():\n",
    "    print(f\"{scenario:<10}{metrics['accuracy']:.4f}{'':<2}{metrics['f1']:.4f}{'':<2}\"\n",
    "          f\"{metrics['roc_auc']:.4f}{'':<2}{metrics['attack_success']:.2%}{'':<3}\"\n",
    "          f\"{metrics['avg_confidence']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pennylane",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
