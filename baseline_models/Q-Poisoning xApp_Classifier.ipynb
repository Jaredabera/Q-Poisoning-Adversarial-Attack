{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Preprocessing with Feature Mapping (using ResNet18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/Pennylane/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ea301b/anaconda3/envs/Pennylane/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (6532, 10), Training labels shape: (6532,)\n",
      "Testing data shape: (1634, 10), Testing labels shape: (1634,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "# Constants\n",
    "SOI_PATH = '/home/HardDisk/yared/spectrogram-dataset/soi'\n",
    "CWI_PATH = '/home/HardDisk/yared/spectrogram-dataset/cwi'\n",
    "IMAGE_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Preprocessing and ResNet feature extractor\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])  # Remove last layer\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "# Updated transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to 3 channels (RGB)\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def load_images(folder_path, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = Image.open(img_path)\n",
    "            img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "            features = resnet(img_tensor).cpu().detach().numpy().flatten()\n",
    "            images.append(features)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Load images and labels\n",
    "soi_images, soi_labels = load_images(SOI_PATH, 0)\n",
    "cwi_images, cwi_labels = load_images(CWI_PATH, 1)\n",
    "\n",
    "# Combine and normalize features\n",
    "X = np.array(soi_images + cwi_images)\n",
    "X = (X - X.min()) / (X.max() - X.min())  # Normalize to [0, 1]\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=10)  # I can further adjust the number of components; maybe later\n",
    "X_reduced = pca.fit_transform(X)\n",
    "\n",
    "# Combine labels\n",
    "y = np.array(soi_labels + cwi_labels)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Example output shapes\n",
    "print(f'Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}')\n",
    "print(f'Testing data shape: {X_test.shape}, Testing labels shape: {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set label distribution:\n",
      "Label 0: 4767 samples\n",
      "Label 1: 1765 samples\n",
      "Testing set label distribution:\n",
      "Label 0: 1193 samples\n",
      "Label 1: 441 samples\n"
     ]
    }
   ],
   "source": [
    "# Check the number of samples in each label for training and testing sets\n",
    "train_labels, train_counts = np.unique(y_train, return_counts=True)\n",
    "test_labels, test_counts = np.unique(y_test, return_counts=True)\n",
    "\n",
    "# Print the number of samples for each label in the training set\n",
    "print(\"Training set label distribution:\")\n",
    "for label, count in zip(train_labels, train_counts):\n",
    "    print(f'Label {label}: {count} samples')\n",
    "\n",
    "# Print the number of samples for each label in the testing set\n",
    "print(\"Testing set label distribution:\")\n",
    "for label, count in zip(test_labels, test_counts):\n",
    "    print(f'Label {label}: {count} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Define the Quantum Circuit and QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Quantum device setup\n",
    "n_qubits = 6  # Adjust based on the number of qubits needed\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "# Define the quantum circuit\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def quantum_circuit(inputs, weights):\n",
    "    \"\"\"Define a variational quantum circuit that matches the specified LaTeX structure.\"\"\"\n",
    "\n",
    "    # Step 1: Apply Hadamard gates to each qubit as per the initial superposition setup\n",
    "    for i in range(n_qubits):\n",
    "        qml.Hadamard(wires=i)\n",
    "\n",
    "    # Step 2: Apply specific rotation gates on specified qubits\n",
    "    qml.RX(inputs[0], wires=0)  # Rx on qubit 1\n",
    "    qml.RY(inputs[1], wires=0)  # Ry on qubit 1\n",
    "    qml.RZ(inputs[2], wires=1)  # Rz on qubit 2\n",
    "    qml.RY(inputs[3], wires=2)  # Ry on qubit 3\n",
    "    qml.RZ(inputs[4], wires=2)  # Rz on qubit 3\n",
    "    qml.RX(inputs[5], wires=3)  # Rx on qubit 4\n",
    "\n",
    "    # Step 3: Apply unitary gates (U(alpha), U(beta), ...) as U3 gates\n",
    "    qml.U3(weights[0, 0, 0], weights[0, 0, 1], weights[0, 0, 2], wires=0)  # U(alpha) on qubit 1\n",
    "    qml.U3(weights[0, 1, 0], weights[0, 1, 1], weights[0, 1, 2], wires=1)  # U(beta) on qubit 2\n",
    "    qml.U3(weights[0, 2, 0], weights[0, 2, 1], weights[0, 2, 2], wires=2)  # U(delta) on qubit 3\n",
    "    qml.U3(weights[0, 3, 0], weights[0, 3, 1], weights[0, 3, 2], wires=3)  # U(epsilon) on qubit 4\n",
    "    qml.U3(weights[0, 4, 0], weights[0, 4, 1], weights[0, 4, 2], wires=4)  # U(zeta) on qubit 5\n",
    "    qml.U3(weights[0, 5, 0], weights[0, 5, 1], weights[0, 5, 2], wires=5)  # U(eta) on qubit 6\n",
    "\n",
    "    # Step 4: Apply entangling CNOT gates to match specified connections\n",
    "    qml.CNOT(wires=[0, 1])  # Control qubit 1 to target qubit 2\n",
    "    qml.CNOT(wires=[0, 2])  # Control qubit 1 to target qubit 3\n",
    "    qml.CNOT(wires=[4, 3])  # Control qubit 4 to target qubit 5\n",
    "    qml.CNOT(wires=[3, 2])  # Control qubit 4 to target qubit 3\n",
    "    qml.CNOT(wires=[4, 5])  # Control qubit 4 to target qubit 3\n",
    "\n",
    "    # Step 5: Measurements on all qubits\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "# Define the weight shape dictionary for TorchLayer\n",
    "weights_shape = {\"weights\": (1, n_qubits, 3)}\n",
    "\n",
    "# QNN model that uses the defined quantum circuit\n",
    "qnn = qml.qnn.TorchLayer(quantum_circuit, weights_shape)\n",
    "\n",
    "# Visualize the circuit\n",
    "inputs = np.random.rand(n_qubits)  # Random input values for the gates\n",
    "weights = np.random.rand(1, n_qubits, 3)  # Random weights for the U3 unitaries\n",
    "# fig, ax = qml.draw_mpl(quantum_circuit)(inputs, weights)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Combine ResNet-18 and QNN for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, n_qubits)  # ResNet18 output to qubit input size\n",
    "        self.qnn = qnn\n",
    "        self.output = nn.Linear(n_qubits, 1)  # Binary classification\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.qnn(x)\n",
    "        x = torch.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def quantum_state_poisoning_attack(model, X_batch, y_batch, epsilon=0.1, max_depth=5):\n",
    "    \"\"\"\n",
    "    Quantum State Poisoning Attack based on angle phase-shifting perturbation\n",
    "    \"\"\"\n",
    "    # Clone input and enable gradient computation\n",
    "    X_batch_adv = X_batch.clone().detach().requires_grad_(True)\n",
    "    batch_size, input_size = X_batch.shape\n",
    "\n",
    "    for layer in range(max_depth):\n",
    "        for qubit in range(input_size):\n",
    "            # Compute the initial angles for this layer and qubit\n",
    "            theta = np.pi * layer / max_depth\n",
    "            phi = 2 * np.pi * qubit / input_size\n",
    "\n",
    "            # Apply perturbation formulas for theta and phi\n",
    "            theta_adv = theta + epsilon * np.sin(theta) + (epsilon**2) * (np.sin(theta)**2) \n",
    "            phi_adv = phi + epsilon * np.cos(phi) + (epsilon**2) * (np.cos(phi) **2) \n",
    "\n",
    "            # Convert perturbations to PyTorch tensors\n",
    "            theta_adv_tensor = torch.tensor(theta_adv, dtype=X_batch_adv.dtype, device=X_batch_adv.device)\n",
    "            phi_adv_tensor = torch.tensor(phi_adv, dtype=X_batch_adv.dtype, device=X_batch_adv.device)\n",
    "\n",
    "            # Apply rotation-like perturbations to the data\n",
    "            rotation_z = torch.cos(phi_adv_tensor) * X_batch_adv[:, qubit] - torch.sin(phi_adv_tensor) * X_batch_adv[:, qubit]\n",
    "            rotation_x = torch.sin(theta_adv_tensor) * rotation_z + torch.cos(theta_adv_tensor) * rotation_z\n",
    "\n",
    "            # Update the perturbed batch\n",
    "            X_batch_adv[:, qubit] = rotation_x\n",
    "\n",
    "        # Compute model output and loss after perturbation\n",
    "        output = model(X_batch_adv).squeeze(1)\n",
    "        loss = F.binary_cross_entropy_with_logits(output, y_batch)\n",
    "\n",
    "        # Adjust epsilon adaptively based on loss\n",
    "        if loss > epsilon:\n",
    "            epsilon *= 0.1\n",
    "\n",
    "    return X_batch_adv.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, epsilon, max_depth=5):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    # Iterate through the test data\n",
    "    with torch.no_grad():  # No gradient calculation for testing\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            X_batch_adv = quantum_state_poisoning_attack(model, X_batch, y_batch, epsilon, max_depth)\n",
    "            output = model(X_batch_adv).squeeze(1)\n",
    "            loss = F.binary_cross_entropy(output, y_batch)\n",
    "            test_loss += loss.item() * X_batch.size(0)\n",
    "            predictions = (output > 0.5).float()\n",
    "            test_correct += (predictions == y_batch).float().sum().item()\n",
    "\n",
    "            y_pred.extend(predictions.cpu().numpy())\n",
    "            y_true.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    avg_test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_accuracy = test_correct / len(test_loader.dataset)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    return avg_test_loss, test_accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/25, Train Loss: 0.6905, Train Acc: 0.7242, Val Loss: 0.6859, Val Acc: 0.7406, Test Loss: 0.6899, Test Acc: 0.6475, Precision: 0.1053, Recall: 0.0408, F1 Score: 0.0588\n",
      "\n",
      "Epoch 2/25, Train Loss: 0.6861, Train Acc: 0.7190, Val Loss: 0.6792, Val Acc: 0.7506, Test Loss: 0.6874, Test Acc: 0.6689, Precision: 0.0833, Recall: 0.0227, F1 Score: 0.0357\n",
      "\n",
      "Epoch 3/25, Train Loss: 0.6791, Train Acc: 0.7518, Val Loss: 0.6747, Val Acc: 0.7314, Test Loss: 0.6898, Test Acc: 0.5771, Precision: 0.1966, Recall: 0.1837, F1 Score: 0.1899\n",
      "\n",
      "Epoch 4/25, Train Loss: 0.6679, Train Acc: 0.7164, Val Loss: 0.6590, Val Acc: 0.7391, Test Loss: 0.6851, Test Acc: 0.6108, Precision: 0.1695, Recall: 0.1134, F1 Score: 0.1359\n",
      "\n",
      "Epoch 5/25, Train Loss: 0.6493, Train Acc: 0.7233, Val Loss: 0.6346, Val Acc: 0.7368, Test Loss: 0.6811, Test Acc: 0.6016, Precision: 0.1875, Recall: 0.1429, F1 Score: 0.1622\n",
      "\n",
      "Epoch 6/25, Train Loss: 0.6118, Train Acc: 0.7223, Val Loss: 0.5811, Val Acc: 0.7422, Test Loss: 0.6659, Test Acc: 0.6169, Precision: 0.1612, Recall: 0.0998, F1 Score: 0.1232\n",
      "\n",
      "Epoch 7/25, Train Loss: 0.5606, Train Acc: 0.7290, Val Loss: 0.5348, Val Acc: 0.7467, Test Loss: 0.6532, Test Acc: 0.6230, Precision: 0.1818, Recall: 0.1134, F1 Score: 0.1397\n",
      "\n",
      "Epoch 8/25, Train Loss: 0.5243, Train Acc: 0.7315, Val Loss: 0.5150, Val Acc: 0.7445, Test Loss: 0.6504, Test Acc: 0.6065, Precision: 0.1902, Recall: 0.1406, F1 Score: 0.1617\n",
      "\n",
      "Epoch 9/25, Train Loss: 0.5056, Train Acc: 0.7336, Val Loss: 0.4990, Val Acc: 0.7460, Test Loss: 0.6427, Test Acc: 0.6114, Precision: 0.1830, Recall: 0.1270, F1 Score: 0.1499\n",
      "\n",
      "Epoch 10/25, Train Loss: 0.4950, Train Acc: 0.7388, Val Loss: 0.4958, Val Acc: 0.7460, Test Loss: 0.6457, Test Acc: 0.6071, Precision: 0.2087, Recall: 0.1633, F1 Score: 0.1832\n",
      "\n",
      "Epoch 11/25, Train Loss: 0.4882, Train Acc: 0.7384, Val Loss: 0.4976, Val Acc: 0.7391, Test Loss: 0.6542, Test Acc: 0.5949, Precision: 0.2324, Recall: 0.2177, F1 Score: 0.2248\n",
      "\n",
      "Epoch 12/25, Train Loss: 0.4821, Train Acc: 0.7340, Val Loss: 0.4766, Val Acc: 0.7475, Test Loss: 0.6383, Test Acc: 0.6175, Precision: 0.2032, Recall: 0.1429, F1 Score: 0.1678\n",
      "\n",
      "Epoch 13/25, Train Loss: 0.4770, Train Acc: 0.7334, Val Loss: 0.4735, Val Acc: 0.7391, Test Loss: 0.6422, Test Acc: 0.6138, Precision: 0.2173, Recall: 0.1655, F1 Score: 0.1879\n",
      "\n",
      "Epoch 14/25, Train Loss: 0.4720, Train Acc: 0.7282, Val Loss: 0.4680, Val Acc: 0.7353, Test Loss: 0.6439, Test Acc: 0.6083, Precision: 0.2149, Recall: 0.1701, F1 Score: 0.1899\n",
      "\n",
      "Epoch 15/25, Train Loss: 0.4675, Train Acc: 0.7280, Val Loss: 0.4724, Val Acc: 0.7253, Test Loss: 0.6564, Test Acc: 0.5900, Precision: 0.2427, Recall: 0.2449, F1 Score: 0.2438\n",
      "\n",
      "Epoch 16/25, Train Loss: 0.4640, Train Acc: 0.7190, Val Loss: 0.4653, Val Acc: 0.7246, Test Loss: 0.6545, Test Acc: 0.5887, Precision: 0.2345, Recall: 0.2313, F1 Score: 0.2329\n",
      "\n",
      "Epoch 17/25, Train Loss: 0.4606, Train Acc: 0.7194, Val Loss: 0.4650, Val Acc: 0.7246, Test Loss: 0.6631, Test Acc: 0.5722, Precision: 0.2471, Recall: 0.2857, F1 Score: 0.2650\n",
      "\n",
      "Epoch 18/25, Train Loss: 0.4578, Train Acc: 0.7154, Val Loss: 0.4532, Val Acc: 0.7238, Test Loss: 0.6549, Test Acc: 0.5875, Precision: 0.2370, Recall: 0.2381, F1 Score: 0.2376\n",
      "\n",
      "Epoch 19/25, Train Loss: 0.4553, Train Acc: 0.7183, Val Loss: 0.4499, Val Acc: 0.7292, Test Loss: 0.6568, Test Acc: 0.5869, Precision: 0.2445, Recall: 0.2540, F1 Score: 0.2492\n",
      "\n",
      "Epoch 20/25, Train Loss: 0.4531, Train Acc: 0.7196, Val Loss: 0.4473, Val Acc: 0.7353, Test Loss: 0.6597, Test Acc: 0.5777, Precision: 0.2412, Recall: 0.2630, F1 Score: 0.2516\n",
      "\n",
      "Epoch 21/25, Train Loss: 0.4512, Train Acc: 0.7269, Val Loss: 0.4494, Val Acc: 0.7353, Test Loss: 0.6709, Test Acc: 0.5532, Precision: 0.2487, Recall: 0.3243, F1 Score: 0.2815\n",
      "\n",
      "Epoch 22/25, Train Loss: 0.4496, Train Acc: 0.7361, Val Loss: 0.4485, Val Acc: 0.7422, Test Loss: 0.6769, Test Acc: 0.5520, Precision: 0.2634, Recall: 0.3673, F1 Score: 0.3068\n",
      "\n",
      "Epoch 23/25, Train Loss: 0.4480, Train Acc: 0.7468, Val Loss: 0.4447, Val Acc: 0.7536, Test Loss: 0.6764, Test Acc: 0.5502, Precision: 0.2606, Recall: 0.3628, F1 Score: 0.3033\n",
      "\n",
      "Epoch 24/25, Train Loss: 0.4468, Train Acc: 0.7548, Val Loss: 0.4454, Val Acc: 0.7498, Test Loss: 0.6865, Test Acc: 0.5282, Precision: 0.2656, Recall: 0.4240, F1 Score: 0.3266\n",
      "\n",
      "Epoch 25/25, Train Loss: 0.4456, Train Acc: 0.7564, Val Loss: 0.4369, Val Acc: 0.7651, Test Loss: 0.6780, Test Acc: 0.5453, Precision: 0.2596, Recall: 0.3696, F1 Score: 0.3050\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "## Prepare Data Loaders\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train  # Ensures the class distribution is preserved\n",
    ")\n",
    "\n",
    "train_data = TensorDataset(\n",
    "    torch.tensor(X_train_split, dtype=torch.float32),\n",
    "    torch.tensor(y_train_split, dtype=torch.float32)\n",
    ")\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_data = TensorDataset(\n",
    "    torch.tensor(X_val, dtype=torch.float32),\n",
    "    torch.tensor(y_val, dtype=torch.float32)\n",
    ")\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_data = TensorDataset(\n",
    "    torch.tensor(X_test, dtype=torch.float32),\n",
    "    torch.tensor(y_test, dtype=torch.float32)\n",
    ")\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "input_size = X_train_split.shape[1]  # Number of features after PCA\n",
    "model = HybridModel(input_size=input_size).to(device)\n",
    "\n",
    "# Calculate class weights for imbalanced dataset\n",
    "class_labels, class_counts = np.unique(y_train_split, return_counts=True)\n",
    "total_samples = len(y_train_split)\n",
    "\n",
    "class_weights = [total_samples / (2 * count) if count > 0 else 0.0 for count in class_counts]\n",
    "# class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_split), y=y_train_split)\n",
    "\n",
    "weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=1e-6)\n",
    "\n",
    "epochs = 25\n",
    "loss_values = []\n",
    "accuracy_values = []\n",
    "val_losses = []\n",
    "val_accuracy_values = []\n",
    "epsilon_default = 0.1\n",
    "test_losses = []\n",
    "test_accuracy_values = []\n",
    "\n",
    "def train_model(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase\n",
    "        model.train()  # Set the model to training mode\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(X_batch).squeeze(1)\n",
    "\n",
    "            weights = weights_tensor[y_batch.long()]\n",
    "\n",
    "            loss = F.binary_cross_entropy(output, y_batch, weight=weights)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * X_batch.size(0)  # Accumulate loss\n",
    "            correct += ((output > 0.5) == y_batch).float().sum().item()  # Accumulate correct predictions\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader.dataset)\n",
    "        accuracy = correct / len(train_loader.dataset)\n",
    "\n",
    "        loss_values.append(avg_loss)\n",
    "        accuracy_values.append(accuracy)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        with torch.no_grad():  # Disable gradient calculation for validation\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                output = model(X_batch).squeeze(1)\n",
    "\n",
    "                loss = F.binary_cross_entropy(output, y_batch)\n",
    "                val_loss += loss.item() * X_batch.size(0)  # Accumulate loss\n",
    "                predictions = (output > 0.5).float()\n",
    "                val_correct += (predictions == y_batch).float().sum().item()\n",
    "\n",
    "                y_pred.extend(predictions.cpu().numpy())\n",
    "                y_true.extend(y_batch.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_accuracy = val_correct / len(val_loader.dataset)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracy_values.append(val_accuracy)\n",
    "\n",
    "        # Testing Phase with FGSM after each epoch\n",
    "        avg_test_loss, test_accuracy, precision, recall, f1 = test_model(model, test_loader, epsilon_default)\n",
    "        test_losses.append(avg_test_loss)\n",
    "        test_accuracy_values.append(test_accuracy)\n",
    "        \n",
    "        # Print the result for the current epoch\n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}, \"\n",
    "              f\"Train Loss: {avg_loss:.4f}, Train Acc: {accuracy:.4f}, \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}, \"\n",
    "              f\"Test Loss: {avg_test_loss:.4f}, Test Acc: {test_accuracy:.4f}, \"\n",
    "              f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "\n",
    "train_model(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with epsilon = 0.01\n",
      "Epsilon: 0.01, Test Loss: 0.6816, Test Accuracy: 0.5337, Precision: 0.2464, Recall: 0.3537, F1 Score: 0.2905\n",
      "\n",
      "Testing with epsilon = 0.02\n",
      "Epsilon: 0.02, Test Loss: 0.6812, Test Accuracy: 0.5367, Precision: 0.2492, Recall: 0.3560, F1 Score: 0.2932\n",
      "\n",
      "Testing with epsilon = 0.03\n",
      "Epsilon: 0.03, Test Loss: 0.6808, Test Accuracy: 0.5373, Precision: 0.2504, Recall: 0.3583, F1 Score: 0.2948\n",
      "\n",
      "Testing with epsilon = 0.04\n",
      "Epsilon: 0.04, Test Loss: 0.6804, Test Accuracy: 0.5392, Precision: 0.2532, Recall: 0.3628, F1 Score: 0.2982\n",
      "\n",
      "Testing with epsilon = 0.05\n",
      "Epsilon: 0.05, Test Loss: 0.6800, Test Accuracy: 0.5410, Precision: 0.2559, Recall: 0.3673, F1 Score: 0.3017\n",
      "\n",
      "Testing with epsilon = 0.1\n",
      "Epsilon: 0.10, Test Loss: 0.6780, Test Accuracy: 0.5453, Precision: 0.2596, Recall: 0.3696, F1 Score: 0.3050\n"
     ]
    }
   ],
   "source": [
    "# List of epsilon values to test\n",
    "epsilons = [0.01, 0.02, 0.03, 0.04, 0.05, 0.1]\n",
    "\n",
    "# Dictionary to store results for each epsilon\n",
    "results = {}\n",
    "\n",
    "# Iterate over each epsilon and evaluate the model\n",
    "for epsilon in epsilons:\n",
    "    print(f\"\\nTesting with epsilon = {epsilon}\")\n",
    "    avg_test_loss, test_accuracy, precision, recall, f1 = test_model(model, test_loader, epsilon, max_depth=5)\n",
    "\n",
    "    # Store results\n",
    "    results[epsilon] = {\n",
    "        'Test Loss': avg_test_loss,\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "\n",
    "    # Print results for this epsilon\n",
    "    print(f\"Epsilon: {epsilon:.2f}, \"\n",
    "          f\"Test Loss: {avg_test_loss:.4f}, \"\n",
    "          f\"Test Accuracy: {test_accuracy:.4f}, \"\n",
    "          f\"Precision: {precision:.4f}, \"\n",
    "          f\"Recall: {recall:.4f}, \"\n",
    "          f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the loss and accuracy values into one graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot loss and accuracy\n",
    "def plot_loss_accuracy(loss_values, val_losses, accuracy_values, val_accuracy_values):\n",
    "    epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot Loss (Training and Validation)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss_values, label='Training Loss', color='blue', marker='o', markersize=4, linestyle='-')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss', color='red', marker='s', markersize=4, linestyle='--')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy (Training and Validation)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy_values, label='Training Accuracy', color='orange', marker='o', markersize=4, linestyle='-')\n",
    "    plt.plot(epochs, val_accuracy_values, label='Validation Accuracy', color='green', marker='s', markersize=4, linestyle='--')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the plotting function after training\n",
    "plot_loss_accuracy(loss_values, val_losses, accuracy_values, val_accuracy_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot loss and accuracy\n",
    "def plot_loss_accuracy(loss_values, accuracy_values):\n",
    "    epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "    plt.figure(figsize=(8, 3))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss_values, label='Loss', color='blue')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy_values, label='Accuracy', color='orange')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8, 3))\n",
    "    # Plot val loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, val_losses, label='Accuracy', color='blue')\n",
    "    plt.title('Validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot val accu\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, val_accuracy_values, label='Accuracy', color='orange')\n",
    "    plt.title('Validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the plotting function after training\n",
    "plot_loss_accuracy(loss_values, accuracy_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "\n",
    "def plot_loss_accuracy(loss_values, accuracy_values):\n",
    "    # Get current directory and create paths\n",
    "    current_dir = os.getcwd()\n",
    "    pdf_path = os.path.join(current_dir, 'training_plot.pdf')\n",
    "    png_path = os.path.join(current_dir, 'training_plot.png')\n",
    "    \n",
    "    # Set up the plot with your original dimensions\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    \n",
    "    # Plot Loss (left y-axis) with enhanced styling\n",
    "    plt.plot(range(1, len(loss_values) + 1), \n",
    "            loss_values, \n",
    "            label='Loss', \n",
    "            color='#1f77b4',\n",
    "            marker='o',\n",
    "            markerfacecolor='white',\n",
    "            markeredgecolor='#1f77b4',\n",
    "            markeredgewidth=1.5,\n",
    "            markersize=4)\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss', color='#1f77b4')\n",
    "    plt.tick_params(axis='y', labelcolor='#1f77b4')\n",
    "    \n",
    "    # Plot Accuracy (right y-axis) with enhanced styling\n",
    "    ax2 = plt.gca().twinx()\n",
    "    ax2.plot(range(1, len(accuracy_values) + 1), \n",
    "            accuracy_values, \n",
    "            label='Accuracy', \n",
    "            color='#ff7f0e',\n",
    "            marker='s',\n",
    "            markerfacecolor='white',\n",
    "            markeredgecolor='#ff7f0e',\n",
    "            markeredgewidth=1.5,\n",
    "            markersize=4)\n",
    "    \n",
    "    ax2.set_ylabel('Accuracy', color='#ff7f0e')\n",
    "    ax2.tick_params(axis='y', labelcolor='#ff7f0e')\n",
    "    \n",
    "    # Add titles and legends as in your original\n",
    "    plt.title('Loss and Accuracy over Epochs')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save high quality versions\n",
    "    plt.savefig(pdf_path, format='pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(png_path, format='png', dpi=600, bbox_inches='tight')\n",
    "    print(f\"Files saved to:\\n{pdf_path}\\n{png_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Your original function call remains the same\n",
    "plot_loss_accuracy(loss_values, accuracy_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def test_model(model, test_loader, epsilon, device, max_depth=5):\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    # Iterate through the test data\n",
    "    with torch.no_grad():  # No gradient calculation for testing\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            # Apply quantum state poisoning attack\n",
    "            X_batch_adv = quantum_state_poisoning_attack(model, X_batch, y_batch, epsilon, max_depth)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(X_batch_adv).squeeze(1)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = F.binary_cross_entropy(output, y_batch.float())\n",
    "            test_loss += loss.item() * X_batch.size(0)\n",
    "            \n",
    "            # Predictions\n",
    "            predictions = (output > 0.5).float()\n",
    "            test_correct += (predictions == y_batch).float().sum().item()\n",
    "            \n",
    "            # Collect predictions and true labels\n",
    "            y_pred.extend(predictions.cpu().detach().numpy())\n",
    "            y_true.extend(y_batch.cpu().detach().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_accuracy = test_correct / len(test_loader.dataset)\n",
    "    \n",
    "    # Compute sklearn metrics\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    return avg_test_loss, test_accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X and y are your features and labels for training data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)  # 20% for validation\n",
    "\n",
    "# Prepare data loaders for training and validation\n",
    "train_data = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train))\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_data = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val))\n",
    "validation_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "y_pred = []\n",
    "y_true = []\n",
    "    \n",
    "# Assuming y_true and y_pred are numpy arrays or lists of predictions and true labels\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "roc_auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pennylane",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
