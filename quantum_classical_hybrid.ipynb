{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34423c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What we do ---quantum-classical Hybrid ResNet-18 + Q-CNN as for O-RAN xApp\n",
    "\"\"\n",
    "# This notebook demonstrates a quantum-classical hybrid model for spectrogram IQ classification in intelligent O-RAN.\n",
    "\n",
    "# Highlights:\n",
    "# - Classical ResNet-18 as a feature extractor\n",
    "# - Quantum Convolutional Layers with 6-qubit circuits (PennyLane)\n",
    "# - Attention-based quantum-classical fusion\n",
    "# - Custom loss & quantum-inspired data augmentation\n",
    "\n",
    "# - Updated for PennyLane, PyTorch, and xApp-oriented data pipeline\n",
    "# Author: Jared A.Ergu\n",
    "# License: CIS Lab--R301B, CCU, Taiwan\n",
    "\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c0f00b",
   "metadata": {},
   "source": [
    " # Part 2: Environment Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a4c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my imports & Configuration\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List\n",
    "import logging\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9016eb3",
   "metadata": {},
   "source": [
    "# Part 3: Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9286388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to configure model\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    resnet_pretrained: bool = True\n",
    "    resnet_freeze_layers: int = 4\n",
    "    feature_dim: int = 512\n",
    "    n_qubits: int = 6\n",
    "    n_layers: int = 4\n",
    "    quantum_backend: str = \"lightning.qubit\"\n",
    "    quantum_shots: int = 1024\n",
    "    num_classes: int = 2\n",
    "    learning_rate: float = 1e-4\n",
    "    batch_size: int = 32\n",
    "    dropout_rate: float = 0.3\n",
    "    use_quantum_data_encoding: bool = True\n",
    "    angle_embedding_type: str = \"amplitude\"\n",
    "    input_channels: int = 3\n",
    "    image_size: int = 224\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a0e2f6",
   "metadata": {},
   "source": [
    "# QuantumLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5339af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QuantumLayer - parameterized 6-qubit circuit\n",
    "class QuantumLayer(nn.Module):\n",
    "    def __init__(self, n_qubits: int = 6, n_layers: int = 4, backend: str = \"lightning.qubit\"):\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "        self.dev = qml.device(backend, wires=n_qubits)\n",
    "\n",
    "        self.params = nn.Parameter(torch.randn(n_layers, n_qubits, 3) * 0.1)\n",
    "        self.phase_params = nn.Parameter(torch.randn(n_layers, n_qubits) * 0.05)\n",
    "\n",
    "        self.qnode = qml.QNode(self._circuit, self.dev, interface=\"torch\")\n",
    "\n",
    "    def _circuit(self, inputs, params, phase_params):\n",
    "        # Input encoding and initial phase injection\n",
    "        for i in range(self.n_qubits):\n",
    "            qml.RY(inputs[i % len(inputs)], wires=i)\n",
    "            qml.RZ(phase_params[0, i], wires=i)\n",
    "\n",
    "        # Variational circuit with entanglement and phase layers\n",
    "        for layer in range(self.n_layers):\n",
    "            for q in range(self.n_qubits):\n",
    "                qml.RX(params[layer, q, 0], wires=q)\n",
    "                qml.RY(params[layer, q, 1], wires=q)\n",
    "                qml.RZ(params[layer, q, 2], wires=q)\n",
    "\n",
    "            for q in range(self.n_qubits - 1):\n",
    "                qml.CNOT(wires=[q, q + 1])\n",
    "            qml.CNOT(wires=[self.n_qubits - 1, 0])\n",
    "\n",
    "            if layer % 2 == 1:\n",
    "                for q in range(1, self.n_qubits):\n",
    "                    qml.CZ(wires=[0, q])\n",
    "                if self.n_qubits >= 4:\n",
    "                    qml.CZ(wires=[1, 3])\n",
    "                    qml.CZ(wires=[2, 4])\n",
    "                if self.n_qubits == 6:\n",
    "                    qml.CZ(wires=[1, 5])\n",
    "\n",
    "            for q in range(self.n_qubits):\n",
    "                qml.PhaseShift(phase_params[layer, q], wires=q)\n",
    "\n",
    "        # Measurement in Pauli basis\n",
    "        return [\n",
    "            qml.expval(qml.PauliZ(wires=0)),\n",
    "            qml.expval(qml.PauliX(wires=1)),\n",
    "            qml.expval(qml.PauliY(wires=2)),\n",
    "            qml.expval(qml.PauliZ(wires=3)),\n",
    "            qml.expval(qml.PauliX(wires=4)),\n",
    "            qml.expval(qml.PauliY(wires=5)),\n",
    "        ]\n",
    "        return torch.stack(outputs)\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x_norm = torch.tanh(x) * np.pi\n",
    "        outputs = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            xi = x_norm[i]\n",
    "            xi = xi[:self.n_qubits] if xi.shape[0] > self.n_qubits else F.pad(xi, (0, self.n_qubits - xi.shape[0]))\n",
    "\n",
    "            out = self.qnode(xi, self.params, self.phase_params)\n",
    "            if isinstance(out, list):\n",
    "                out_tensor = torch.stack(out)\n",
    "            else:\n",
    "                out_tensor = out\n",
    "\n",
    "            outputs.append(out_tensor)\n",
    "\n",
    "        return torch.stack(outputs).float()  # âœ… FIX: ensure float32 for torch.Linear compatibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eddee2d",
   "metadata": {},
   "source": [
    "# QuantumConvolutionalLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c37b412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QuantumConvolutionalLayer - Spectrogram Feature to Quantum Patch Encoder\n",
    "class QuantumConvolutionalLayer(nn.Module):\n",
    "    def __init__(self, n_qubits: int = 6, n_layers: int = 4, kernel_size: int = 3, stride: int = 1):\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "        # Core quantum processor\n",
    "        self.quantum_layer = QuantumLayer(n_qubits, n_layers)\n",
    "\n",
    "        # Classical post-processing after quantum circuit\n",
    "        self.post_process = nn.Sequential(\n",
    "            nn.Linear(n_qubits, n_qubits * 2),\n",
    "            nn.LayerNorm(n_qubits * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(n_qubits * 2, n_qubits),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        # Project high-dim input to match quantum input size if needed\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool1d(n_qubits)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Spectrogram tensor (B, C, H, W)\n",
    "        Returns:\n",
    "            Quantum-processed features (B, n_qubits)\n",
    "        \"\"\"\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        # Extract temporal features: Mean over frequency (height)\n",
    "        temporal = torch.mean(x, dim=2).view(B, -1)\n",
    "\n",
    "        # Extract spectral features: Mean over time (width)\n",
    "        spectral = torch.mean(x, dim=3).view(B, -1)\n",
    "\n",
    "        # Combine frequency-time features\n",
    "        combined = torch.cat([temporal, spectral], dim=1)\n",
    "\n",
    "        # Pool or pad to match quantum input size\n",
    "        if combined.shape[1] > self.n_qubits:\n",
    "            combined = self.adaptive_pool(combined.unsqueeze(1)).squeeze(1)\n",
    "        elif combined.shape[1] < self.n_qubits:\n",
    "            combined = F.pad(combined, (0, self.n_qubits - combined.shape[1]))\n",
    "\n",
    "        # Run through quantum circuit\n",
    "        quantum_out = self.quantum_layer(combined)\n",
    "\n",
    "        # Classical post-quantum processing\n",
    "        return self.post_process(quantum_out)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0c7e5",
   "metadata": {},
   "source": [
    "# ResNetQuantumHybrid --> the full model pipeline that ties ResNet + Quantum layers + attention + classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6288a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNetQuantumHybrid - Full xApp-Oriented Model with Dual Quantum Paths\n",
    "class ResNetQuantumHybrid(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        # Backbone Feature Extractor (ResNet-18)\n",
    "        self.resnet_backbone = self._build_resnet_backbone()\n",
    "\n",
    "        #  Dimensionality Reduction Head for ResNet Output\n",
    "        self.feature_reducer = nn.Sequential(\n",
    "            nn.Linear(512, config.feature_dim),\n",
    "            nn.BatchNorm1d(config.feature_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout_rate),\n",
    "            nn.Linear(config.feature_dim, config.n_qubits * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout_rate * 0.5)\n",
    "        )\n",
    "\n",
    "        # Dual Quantum Convolutional Pipelines\n",
    "        self.quantum_conv1 = QuantumConvolutionalLayer(config.n_qubits, config.n_layers)\n",
    "        self.quantum_conv2 = QuantumConvolutionalLayer(config.n_qubits, max(2, config.n_layers // 2))\n",
    "\n",
    "        # Final Quantum Fusion Layer\n",
    "        self.quantum_fusion = QuantumLayer(config.n_qubits, config.n_layers)\n",
    "\n",
    "        # Multihead Attention Between Classical and Quantum\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=config.n_qubits,\n",
    "            num_heads=2,\n",
    "            dropout=config.dropout_rate,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Learnable Feature Fusion Weights\n",
    "        self.fusion_weights = nn.Parameter(torch.tensor([0.7, 0.3]))\n",
    "\n",
    "        # Final Classification Head\n",
    "        self.classifier_head = nn.Sequential(\n",
    "            nn.Linear(config.n_qubits, config.n_qubits * 3),\n",
    "            nn.LayerNorm(config.n_qubits * 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout_rate),\n",
    "            nn.Linear(config.n_qubits * 3, config.n_qubits * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout_rate * 0.5),\n",
    "            nn.Linear(config.n_qubits * 2, config.num_classes)\n",
    "        )\n",
    "\n",
    "    def _build_resnet_backbone(self) -> nn.Module:\n",
    "        resnet = models.resnet18(pretrained=self.config.resnet_pretrained)\n",
    "\n",
    "        # Modify input channel if spectrograms have different format\n",
    "        if self.config.input_channels != 3:\n",
    "            resnet.conv1 = nn.Conv2d(\n",
    "                self.config.input_channels, 64, kernel_size=7, stride=2,\n",
    "                padding=3, bias=False\n",
    "            )\n",
    "\n",
    "        # Remove the final FC classifier\n",
    "        resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "        # Freeze early layers\n",
    "        for i, child in enumerate(resnet.children()):\n",
    "            if i < self.config.resnet_freeze_layers:\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "        return resnet\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        B = x.shape[0]\n",
    "\n",
    "        # Step 1: Classical feature extraction\n",
    "        classical_feat = self.resnet_backbone(x).view(B, -1)\n",
    "        classical_feat = self.feature_reducer(classical_feat)\n",
    "\n",
    "        # Step 2: Quantum pathway 1 and 2\n",
    "        qfeat1 = self.quantum_conv1(x)\n",
    "        qfeat2 = self.quantum_conv2(x)\n",
    "\n",
    "        # Step 3: Learnable quantum combination\n",
    "        alpha = torch.sigmoid(self.fusion_weights[0])\n",
    "        beta = torch.sigmoid(self.fusion_weights[1])\n",
    "        combined_qfeat = (alpha * qfeat1 + beta * qfeat2) / (alpha + beta)\n",
    "\n",
    "        # Step 4: Quantum fusion\n",
    "        fused_qfeat = self.quantum_fusion(combined_qfeat)\n",
    "\n",
    "        # Step 5: Attention between classical and quantum\n",
    "        q_input = fused_qfeat.unsqueeze(1)\n",
    "        c_input = classical_feat[:, :self.config.n_qubits].unsqueeze(1)\n",
    "        attended_q, attn_weights = self.attention(q_input, q_input, q_input)\n",
    "        attended_q = attended_q.squeeze(1)\n",
    "\n",
    "        # Step 6: Final fusion and classification\n",
    "        final_feat = attended_q + 0.1 * c_input.squeeze(1)\n",
    "        logits = self.classifier_head(final_feat)\n",
    "\n",
    "        return {\n",
    "            \"logits\": logits,\n",
    "            \"classical_features\": classical_feat,\n",
    "            \"quantum_features\": fused_qfeat,\n",
    "            \"attention_weights\": attn_weights.squeeze(1),\n",
    "            \"combined_features\": final_feat,\n",
    "            \"quantum_pathway1\": qfeat1,\n",
    "            \"quantum_pathway2\": qfeat2\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003d6c4b",
   "metadata": {},
   "source": [
    "# QuantumLoss â€” combining CE loss + quantum regularization + pathway alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "683fd61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QuantumLoss - Total Loss for Quantum-Classical Hybrid Model\n",
    "class QuantumLoss(nn.Module):\n",
    "    def __init__(self, alpha: float = 0.1, beta: float = 0.05, gamma: float = 0.02):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha  # Regularization\n",
    "        self.beta = beta    # Coherence penalty\n",
    "        self.gamma = gamma  # Pathway alignment\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, outputs: Dict[str, torch.Tensor], targets: torch.Tensor,\n",
    "                model: ResNetQuantumHybrid) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Compute loss components and aggregate\n",
    "        \"\"\"\n",
    "        # ðŸ”¹ 1. Classical cross-entropy\n",
    "        ce = self.ce_loss(outputs['logits'], targets)\n",
    "\n",
    "        # ðŸ”¹ 2. Quantum regularization (L2 norm on parameters)\n",
    "        reg = 0\n",
    "        n = 0\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, QuantumLayer):\n",
    "                reg += torch.norm(module.params, p=2)\n",
    "                if hasattr(module, 'phase_params'):\n",
    "                    reg += torch.norm(module.phase_params, p=2)\n",
    "                n += 1\n",
    "        if n > 0:\n",
    "            reg /= n\n",
    "\n",
    "        #  3. Quantum coherence loss (maximize feature std dev)\n",
    "        q_feat = outputs['quantum_features']\n",
    "        coherence = -torch.mean(torch.std(q_feat, dim=1))\n",
    "\n",
    "        #  4. Pathway consistency (MSE between two Q-features)\n",
    "        if 'quantum_pathway1' in outputs and 'quantum_pathway2' in outputs:\n",
    "            align = F.mse_loss(outputs['quantum_pathway1'], outputs['quantum_pathway2'])\n",
    "        else:\n",
    "            align = torch.tensor(0.0, device=q_feat.device)\n",
    "\n",
    "        #  5. Combine all\n",
    "        total = ce + self.alpha * reg + self.beta * coherence + self.gamma * align\n",
    "\n",
    "        return {\n",
    "            \"total_loss\": total,\n",
    "            \"ce_loss\": ce,\n",
    "            \"quantum_reg\": reg,\n",
    "            \"coherence_loss\": coherence,\n",
    "            \"pathway_consistency\": align\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dd1990",
   "metadata": {},
   "source": [
    "# QuantumDataAugmentation --> quantum-inspired transformations for spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a2cac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QuantumDataAugmentation - Quantum-inspired spectrogram augmenting\n",
    "class QuantumDataAugmentation:\n",
    "    @staticmethod\n",
    "    def quantum_noise_injection(x: torch.Tensor, noise_level: float = 0.1) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Simulating quantum measurement noise and bit-flip errors\n",
    "        \"\"\"\n",
    "        noise = torch.randn_like(x) * noise_level\n",
    "        pauli_noise = torch.rand_like(x)\n",
    "        mask = pauli_noise < 0.06  # 6% bit-flip probability\n",
    "        noisy_x = x + noise\n",
    "        noisy_x[mask] *= -1  # simulate Pauli-X flip\n",
    "        return torch.clamp(noisy_x, 0, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def quantum_rotation_augmentation(x: torch.Tensor, max_angle: float = 0.1) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Simulates phase shifts by applying sine-cosine mixing with random angles\n",
    "        \"\"\"\n",
    "        angles = (torch.rand_like(x) * 2 - 1) * max_angle  # Uniform in [-max_angle, +max_angle]\n",
    "        rotated_x = x * torch.cos(angles) + torch.randn_like(x) * torch.sin(angles) * 0.1\n",
    "        return torch.clamp(rotated_x, 0, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def spectrogram_quantum_transform(x: torch.Tensor, n_qubits: int = 6) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Applies frequency-specific quantum-like transforms to simulate entanglement variance\n",
    "        \"\"\"\n",
    "        B, C, H, W = x.shape\n",
    "        freq_weights = torch.randn(n_qubits, device=x.device) * 0.1\n",
    "        freq_indices = torch.linspace(0, H - 1, n_qubits).long()\n",
    "\n",
    "        for i, freq_idx in enumerate(freq_indices):\n",
    "            if freq_idx < H:\n",
    "                x[:, :, freq_idx, :] *= (1 + freq_weights[i])\n",
    "\n",
    "        return torch.clamp(x, 0, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76438514",
   "metadata": {},
   "source": [
    "# Utility Functions (create_hybrid_model, count_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bb20c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: Model Factory + Parameter Counter\n",
    "def create_hybrid_model(config: ModelConfig) -> ResNetQuantumHybrid:\n",
    "    \"\"\"\n",
    "    Factory function for initializing the hybrid model with proper quantum parameter init\n",
    "    \"\"\"\n",
    "    logger.info(f\" Initializing hybrid model with {config.n_qubits} qubits and {config.n_layers} quantum layers...\")\n",
    "    model = ResNetQuantumHybrid(config)\n",
    "\n",
    "    # Xavier (Glorot) initialization for trainable quantum parameters\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, QuantumLayer):\n",
    "            if module.params.data.ndim >= 2:\n",
    "                nn.init.xavier_uniform_(module.params.data)\n",
    "            else:\n",
    "                module.params.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "            if hasattr(module, 'phase_params'):\n",
    "                module.phase_params.data.uniform_(-0.05, 0.05)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def count_parameters(model: nn.Module) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Counts classical and quantum parameters for reporting\n",
    "    \"\"\"\n",
    "    classical = 0\n",
    "    quantum = 0\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'quantum' in name.lower() or 'params' in name:\n",
    "            quantum += param.numel()\n",
    "        else:\n",
    "            classical += param.numel()\n",
    "\n",
    "    return {\n",
    "        'classical_parameters': classical,\n",
    "        'quantum_parameters': quantum,\n",
    "        'total_parameters': classical + quantum\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60df07b",
   "metadata": {},
   "source": [
    "# Forward Pass checkingg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf998d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/Pennylane/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ea301b/anaconda3/envs/Pennylane/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model Created Successfully!\n",
      " Classical Params: 11,315,106\n",
      "Quantum Params: 612\n",
      "Total Params:    11,315,718\n",
      " Logits shape: torch.Size([2, 2])\n",
      " Quantum feature shape: torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "# Quick Check - Forward Pass\n",
    "if __name__ == \"__main__\":\n",
    "    config = ModelConfig(\n",
    "        n_qubits=6,\n",
    "        n_layers=4,\n",
    "        num_classes=2,\n",
    "        feature_dim=256,\n",
    "        input_channels=3  # RGB spectrograms\n",
    "    )\n",
    "\n",
    "    model = create_hybrid_model(config)\n",
    "    param_count = count_parameters(model)\n",
    "\n",
    "    print(\"Hybrid Model Created Successfully!\")\n",
    "    print(f\" Classical Params: {param_count['classical_parameters']:,}\")\n",
    "    print(f\"Quantum Params: {param_count['quantum_parameters']:,}\")\n",
    "    print(f\"Total Params:    {param_count['total_parameters']:,}\")\n",
    "\n",
    "    # Dummy spectrogram input (batch size 2)\n",
    "    test_input = torch.randn(2, 3, 224, 224)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(test_input)\n",
    "        print(\" Logits shape:\", outputs['logits'].shape)\n",
    "        print(\" Quantum feature shape:\", outputs['quantum_features'].shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pennylane",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
